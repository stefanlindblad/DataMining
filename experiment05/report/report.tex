\documentclass[12pt,a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{ngerman}
\usepackage{url}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{eurosym}
\usepackage{biblatex}
\usepackage{url}
\usepackage{color}
\usepackage{listings}
\usepackage{hyperref}
\usepackage[table]{xcolor}
\linespread{1.4}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mylightgray}{rgb}{0.7,0.7,0.7}
\definecolor{mylightergray}{rgb}{0.9,0.9,0.9}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\let\origitemize\itemize
\def\itemize{\origitemize\itemsep0pt}

\lstset{ 
  backgroundcolor=\color{white},   
  basicstyle=\ttfamily\footnotesize,          
  breakatwhitespace=false,         
  breaklines=true,  
  commentstyle=\color{mygreen}, 
  escapeinside={\%*}{*)}, 
  extendedchars=true,             
  keepspaces=true,                 
  keywordstyle=\color{blue},
  language=Octave,
  numbers=left,                   
  numbersep=15pt,                  
  numberstyle=\tiny\color{mygray}, 
  showspaces=false,                
  showstringspaces=false,          
  showtabs=false,                  
  stringstyle=\color{mymauve},
  tabsize=2,
  title=\lstname,
  captionpos=b
}

\renewcommand*\lstlistingname{Codebeispiel}    %Rename Listings

\renewcommand*\thesection{\arabic{section}}

\makeatletter
\renewcommand\paragraph{\@startsection{subparagraph}{5}{\parindent}%
    {3.25ex \@plus1ex \@minus .2ex}%
    {0.75ex plus 0.1ex}% space after heading
    {\normalfont\normalsize\bfseries}}
\makeatother

\begin{document}
\title{Praktikum Data Mining}
\subtitle{Gesichtserkennung}
\author{Oliver Fesseler \and Maria Florus\ss \and Stefan Seibert \and  Daniel Grie\ss haber}
\maketitle
\newpage

\part*{Durchf\"uhrung des Versuchs}

\section*{Ab welcher Anzahl K von verwendeten Eigenvektoren treten Fehlklassifikationen ein?}
Im empirischen Versuch haben wir herausgefunden, dass ab einer Merkmalsanzahl von $K < 6$ bei der Erkennung des Bildes 1-1.png aus dem Testdatensatz die erste Fehlklassifikation auftritt.

\section*{Wie gro{\ss} ist dann die Mindestdistanz zwischen Test- und nächstliegendem Trainingsbild?}
Die niedrigste Distanz mit $K=6$ bei Klassifizierung des Bildes 1-1.png beträgt $841.01688805$.

\section*{Wie ändert sich die Distanz zwischen Bildern, wenn die Anzahl der Eigenvektoren reduziert wird?}

Distanzen werden mit einer höheren Anzahl von Merkmalen $K$ größer, da die Anzahl an Dimensionen in denen die Distanz berechnet wird steigt.

 \begin{table}[h!]

 \centering
 
 \begin{tabular}{l r r}
 & $K=5$ & $K=6$ \\
 1-2.png & 758.3467758 & 841.01688805 \\
 3-3.png & 549.501226082 & 1226.39019008 \\
 \end{tabular}
 \caption*{Distanzen der kritischen Bilder bei unterschiedlicher Merkmalsanzahl}
 \end{table} 

\section*{Wie könnte dieser Einfuss der Eigenvektor-Anzahl auf die Mindestdistanz reduziert werden?}
Um die Abhängigkeit aufzulösen kann die Distanz mit der Eigenvektor-Anzahl normiert werden.

\begin{equation*}
d_N = \frac{d}{K}
\end{equation*}

\section*{Nennen Sie zwei Algorithmus-unabhängige Parameter, die starken Einfluss auf die Rate korrekter Gesichtserkennungen haben}

\paragraph{Eigenschaften der Bilder}
\begin{itemize}
\item Gleicher Bildmodus, wie zum Beispiel RGB oder L (Grayscale)
\item Aufnahmewinkel
\item gleicher Hintergrund
\item Beleuchtung
\item Bildschärfe
\item Gesicht klar erkennbar (Brillen, Haare im Gesicht, etc.)
\end{itemize}

\paragraph{Anzahl der Trainingsbildern}
Mit steigender Anzahl an Trainingsbildern pro Person steigt die Erkennungsrate.

\end{document}


